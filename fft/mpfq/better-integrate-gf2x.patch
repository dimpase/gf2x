diff --git a/fft/mpfq/i386/mpfq_2_128.h b/fft/mpfq/i386/mpfq_2_128.h
index eefa0d5..9cb92eb 100644
--- a/fft/mpfq/i386/mpfq_2_128.h
+++ b/fft/mpfq/i386/mpfq_2_128.h
@@ -11,9 +11,12 @@
 #include <assert.h>
 #include <stdint.h>
 #include <ctype.h>
-#include <emmintrin.h>
 #include <stddef.h>
 #include <stdio.h>
+#ifdef  HAVE_GF2X
+#include "gf2x.h"
+#endif
+
 #include "assert.h"
 #ifdef	MPFQ_LAST_GENERATED_TAG
 #undef	MPFQ_LAST_GENERATED_TAG
@@ -1034,139 +1037,74 @@ void mpfq_2_128_elt_ur_add(mpfq_2_128_dst_field K MAYBE_UNUSED, mpfq_2_128_dst_e
 }
 
 /* *Mpfq::gf2n::mul::code_for_mul_ur */
+#ifndef HAVE_GF2X
+/* include something not too dumb, although we don't really care */
+static inline void
+mpfq_2_128_gf2x_mul1 (unsigned long *c, unsigned long a, unsigned long b)
+{
+   unsigned long hi, lo, tmp, A[16];
+   A[0]  = 0;         A[1]  = a;         A[2]  = A[1] << 1; A[3]  = A[2] ^ a;
+   A[4]  = A[2] << 1; A[5]  = A[4] ^ a;  A[6]  = A[3] << 1; A[7]  = A[6] ^ a;
+   A[8]  = A[4] << 1; A[9]  = A[8] ^ a;  A[10] = A[5] << 1; A[11] = A[10] ^ a;
+   A[12] = A[6] << 1; A[13] = A[12] ^ a; A[14] = A[7] << 1; A[15] = A[14] ^ a;
+   lo = (A[b >> 28] << 4) ^ A[(b >> 24) & 15];
+   hi = lo >> 24;
+   lo = (lo << 8) ^ (A[(b >> 20) & 15] << 4) ^ A[(b >> 16) & 15];
+   hi = (hi << 8) | (lo >> 24);
+   lo = (lo << 8) ^ (A[(b >> 12) & 15] << 4) ^ A[(b >> 8) & 15];
+   hi = (hi << 8) | (lo >> 24);
+   lo = (lo << 8) ^ (A[(b >> 4) & 15] << 4) ^ A[b & 15];
+   tmp = -((a >> 31) & 1); tmp &= ((b & 0xfefefefe) >> 1); hi = hi ^ tmp;
+   tmp = -((a >> 30) & 1); tmp &= ((b & 0xfcfcfcfc) >> 2); hi = hi ^ tmp;
+   tmp = -((a >> 29) & 1); tmp &= ((b & 0xf8f8f8f8) >> 3); hi = hi ^ tmp;
+   tmp = -((a >> 28) & 1); tmp &= ((b & 0xf0f0f0f0) >> 4); hi = hi ^ tmp;
+   tmp = -((a >> 27) & 1); tmp &= ((b & 0xe0e0e0e0) >> 5); hi = hi ^ tmp;
+   tmp = -((a >> 26) & 1); tmp &= ((b & 0xc0c0c0c0) >> 6); hi = hi ^ tmp;
+   tmp = -((a >> 25) & 1); tmp &= ((b & 0x80808080) >> 7); hi = hi ^ tmp;
+   c[0] = lo; c[1] = hi;
+}
+static inline void mpfq_2_128_gf2x_mul2(unsigned long *c, const unsigned long *a,
+			     const unsigned long *b)
+{
+    unsigned long t;
+    unsigned long u[2];
+
+    mpfq_2_128_gf2x_mul1(c, a[0], b[0]);
+    mpfq_2_128_gf2x_mul1(c + 2, a[1], b[1]);
+    t = c[1] ^ c[2];
+    mpfq_2_128_gf2x_mul1(u, a[0] ^ a[1], b[0] ^ b[1]);
+    c[1] = c[0] ^ u[0] ^ t;
+    c[2] = c[3] ^ u[1] ^ t;
+}
+static inline void mpfq_2_128_gf2x_mul4(unsigned long *c, const unsigned long *a,
+		   const unsigned long *b)
+{
+    unsigned long aa[2], bb[2], ab[4];
+    unsigned long lo[4], hi[4];
+    mpfq_2_128_gf2x_mul2(lo, a, b);
+    mpfq_2_128_gf2x_mul2(hi, a + 2, b + 2);
+    aa[0] = a[0] ^ a[2];
+    aa[1] = a[1] ^ a[3];
+    bb[0] = b[0] ^ b[2];
+    bb[1] = b[1] ^ b[3];
+    unsigned long c24 = lo[2] ^ hi[0];
+    unsigned long c35 = lo[3] ^ hi[1];
+    mpfq_2_128_gf2x_mul2(ab, aa, bb);
+    c[0] = lo[0];
+    c[1] = lo[1];
+    c[2] = ab[0] ^ lo[0] ^ c24;
+    c[3] = ab[1] ^ lo[1] ^ c35;
+    c[4] = ab[2] ^ hi[2] ^ c24;
+    c[5] = ab[3] ^ hi[3] ^ c35;
+    c[6] = hi[2];
+    c[7] = hi[3];
+}
+#endif
+
 static inline
 void mpfq_2_128_mul_ur(mpfq_2_128_dst_field K MAYBE_UNUSED, mpfq_2_128_dst_elt_ur t, mpfq_2_128_src_elt s1, mpfq_2_128_src_elt s2)
 {
-    /* 128x128 basecase slice=4 slicenet=sequence sse2=64 w=32 */
-#define SHL(x, r) _mm_slli_epi64((x), (r))
-#define SHR(x, r) _mm_srli_epi64((x), (r))
-#define SHLD(x, r) _mm_slli_si128((x), (r) >> 3)
-#define SHRD(x, r) _mm_srli_si128((x), (r) >> 3)
-    /* s2_input_elements: s2[0] s2[1] s2[2] s2[3] */
-    __m128i u;
-    __m128i t0;
-    __m128i t1;
-    __m128i t2;
-    
-    __m128i g[16];
-    /* sequence update walk */
-    g[0] = _mm_setzero_si128();
-    g[1] = _mm_set_epi32(s2[3], s2[2], s2[1], s2[0]);
-    g[2] = SHL(g[1], 1);
-    g[3] = g[2] ^ g[1];
-    g[4] = SHL(g[2], 1);
-    g[5] = g[4] ^ g[1];
-    g[6] = SHL(g[3], 1);
-    g[7] = g[6] ^ g[1];
-    g[8] = SHL(g[4], 1);
-    g[9] = g[8] ^ g[1];
-    g[10] = SHL(g[5], 1);
-    g[11] = g[10] ^ g[1];
-    g[12] = SHL(g[6], 1);
-    g[13] = g[12] ^ g[1];
-    g[14] = SHL(g[7], 1);
-    g[15] = g[14] ^ g[1];
-    
-    /* round 0 */
-    u = g[s1[0]       & 15];
-    t0  = u;
-    u = g[s1[0] >>  4 & 15];
-    t0 ^= SHL(u,  4); t1  = SHR(u, 60);
-    u = g[s1[0] >>  8 & 15];
-    t0 ^= SHL(u,  8); t1 ^= SHR(u, 56);
-    u = g[s1[0] >> 12 & 15];
-    t0 ^= SHL(u, 12); t1 ^= SHR(u, 52);
-    u = g[s1[0] >> 16 & 15];
-    t0 ^= SHL(u, 16); t1 ^= SHR(u, 48);
-    u = g[s1[0] >> 20 & 15];
-    t0 ^= SHL(u, 20); t1 ^= SHR(u, 44);
-    u = g[s1[0] >> 24 & 15];
-    t0 ^= SHL(u, 24); t1 ^= SHR(u, 40);
-    u = g[s1[0] >> 28 & 15];
-    t0 ^= SHL(u, 28); t1 ^= SHR(u, 36);
-    u = g[s1[1]       & 15];
-    t0 ^= SHL(u, 32); t1 ^= SHR(u, 32);
-    u = g[s1[1] >>  4 & 15];
-    t0 ^= SHL(u, 36); t1 ^= SHR(u, 28);
-    u = g[s1[1] >>  8 & 15];
-    t0 ^= SHL(u, 40); t1 ^= SHR(u, 24);
-    u = g[s1[1] >> 12 & 15];
-    t0 ^= SHL(u, 44); t1 ^= SHR(u, 20);
-    u = g[s1[1] >> 16 & 15];
-    t0 ^= SHL(u, 48); t1 ^= SHR(u, 16);
-    u = g[s1[1] >> 20 & 15];
-    t0 ^= SHL(u, 52); t1 ^= SHR(u, 12);
-    u = g[s1[1] >> 24 & 15];
-    t0 ^= SHL(u, 56); t1 ^= SHR(u,  8);
-    u = g[s1[1] >> 28 & 15];
-    t0 ^= SHL(u, 60); t1 ^= SHR(u,  4);
-    
-    /* round 1 */
-    u = g[s1[2]       & 15];
-    t1 ^= u;
-    u = g[s1[2] >>  4 & 15];
-    t1 ^= SHL(u,  4); t2  = SHR(u, 60);
-    u = g[s1[2] >>  8 & 15];
-    t1 ^= SHL(u,  8); t2 ^= SHR(u, 56);
-    u = g[s1[2] >> 12 & 15];
-    t1 ^= SHL(u, 12); t2 ^= SHR(u, 52);
-    u = g[s1[2] >> 16 & 15];
-    t1 ^= SHL(u, 16); t2 ^= SHR(u, 48);
-    u = g[s1[2] >> 20 & 15];
-    t1 ^= SHL(u, 20); t2 ^= SHR(u, 44);
-    u = g[s1[2] >> 24 & 15];
-    t1 ^= SHL(u, 24); t2 ^= SHR(u, 40);
-    u = g[s1[2] >> 28 & 15];
-    t1 ^= SHL(u, 28); t2 ^= SHR(u, 36);
-    u = g[s1[3]       & 15];
-    t1 ^= SHL(u, 32); t2 ^= SHR(u, 32);
-    u = g[s1[3] >>  4 & 15];
-    t1 ^= SHL(u, 36); t2 ^= SHR(u, 28);
-    u = g[s1[3] >>  8 & 15];
-    t1 ^= SHL(u, 40); t2 ^= SHR(u, 24);
-    u = g[s1[3] >> 12 & 15];
-    t1 ^= SHL(u, 44); t2 ^= SHR(u, 20);
-    u = g[s1[3] >> 16 & 15];
-    t1 ^= SHL(u, 48); t2 ^= SHR(u, 16);
-    u = g[s1[3] >> 20 & 15];
-    t1 ^= SHL(u, 52); t2 ^= SHR(u, 12);
-    u = g[s1[3] >> 24 & 15];
-    t1 ^= SHL(u, 56); t2 ^= SHR(u,  8);
-    u = g[s1[3] >> 28 & 15];
-    t1 ^= SHL(u, 60); t2 ^= SHR(u,  4);
-    /* end */
-    
-    /* repair steps */
-    /* repair section 200711-200803 */
-    __m128i v1 = _mpfq_mm_setr_epi32(s1[0], s1[1], s1[0], s1[1]);
-    v1 = SHR(v1, 1);
-    __m128i v2 = _mpfq_mm_setr_epi32(s1[2], s1[3], s1[2], s1[3]);
-    v2 = SHR(v2, 1);
-    __m128i w;
-    __m128i m = _mpfq_mm_setr_epi32_c(0x77777777, 0x77777777, 0x77777777, 0x77777777);
-    w = -SHR(g[1],63);
-    v1 = v1 & m;
-    t1 ^= v1 & w;
-    v2 = v2 & m;
-    t2 ^= v2 & w;
-    w = -SHR(g[2],63);
-    v1 = SHR(v1, 1) & m;
-    t1 ^= v1 & w;
-    v2 = SHR(v2, 1) & m;
-    t2 ^= v2 & w;
-    w = -SHR(g[4],63);
-    v1 = SHR(v1, 1) & m;
-    t1 ^= v1 & w;
-    v2 = SHR(v2, 1) & m;
-    t2 ^= v2 & w;
-    
-    /* store result */
-    _mm_storeu_si128((__m128i *) (t + 0), _mm_xor_si128(t0, SHLD(t1, 64)));
-    _mm_storeu_si128((__m128i *) (t + 4), _mm_xor_si128(t2, SHRD(t1, 64)));
-#undef SHL
-#undef SHR
-#undef SHLD
-#undef SHRD
+    mpfq_2_128_gf2x_mul4(t, s1, s2);
 }
 
 /* *Mpfq::gf2n::squaring::code_for_sqr_ur */
diff --git a/fft/mpfq/i386/mpfq_2_64.h b/fft/mpfq/i386/mpfq_2_64.h
index 7394af5..22c51e0 100644
--- a/fft/mpfq/i386/mpfq_2_64.h
+++ b/fft/mpfq/i386/mpfq_2_64.h
@@ -11,9 +11,12 @@
 #include <assert.h>
 #include <stdint.h>
 #include <ctype.h>
-#include <emmintrin.h>
 #include <stddef.h>
 #include <stdio.h>
+#ifdef  HAVE_GF2X
+#include "gf2x.h"
+#endif
+
 #include "assert.h"
 #ifdef	MPFQ_LAST_GENERATED_TAG
 #undef	MPFQ_LAST_GENERATED_TAG
@@ -956,95 +959,51 @@ void mpfq_2_64_elt_ur_add(mpfq_2_64_dst_field K MAYBE_UNUSED, mpfq_2_64_dst_elt_
 }
 
 /* *Mpfq::gf2n::mul::code_for_mul_ur */
+#ifndef HAVE_GF2X
+/* include something not too dumb, although we don't really care */
+static inline void
+mpfq_2_64_gf2x_mul1 (unsigned long *c, unsigned long a, unsigned long b)
+{
+   unsigned long hi, lo, tmp, A[16];
+   A[0]  = 0;         A[1]  = a;         A[2]  = A[1] << 1; A[3]  = A[2] ^ a;
+   A[4]  = A[2] << 1; A[5]  = A[4] ^ a;  A[6]  = A[3] << 1; A[7]  = A[6] ^ a;
+   A[8]  = A[4] << 1; A[9]  = A[8] ^ a;  A[10] = A[5] << 1; A[11] = A[10] ^ a;
+   A[12] = A[6] << 1; A[13] = A[12] ^ a; A[14] = A[7] << 1; A[15] = A[14] ^ a;
+   lo = (A[b >> 28] << 4) ^ A[(b >> 24) & 15];
+   hi = lo >> 24;
+   lo = (lo << 8) ^ (A[(b >> 20) & 15] << 4) ^ A[(b >> 16) & 15];
+   hi = (hi << 8) | (lo >> 24);
+   lo = (lo << 8) ^ (A[(b >> 12) & 15] << 4) ^ A[(b >> 8) & 15];
+   hi = (hi << 8) | (lo >> 24);
+   lo = (lo << 8) ^ (A[(b >> 4) & 15] << 4) ^ A[b & 15];
+   tmp = -((a >> 31) & 1); tmp &= ((b & 0xfefefefe) >> 1); hi = hi ^ tmp;
+   tmp = -((a >> 30) & 1); tmp &= ((b & 0xfcfcfcfc) >> 2); hi = hi ^ tmp;
+   tmp = -((a >> 29) & 1); tmp &= ((b & 0xf8f8f8f8) >> 3); hi = hi ^ tmp;
+   tmp = -((a >> 28) & 1); tmp &= ((b & 0xf0f0f0f0) >> 4); hi = hi ^ tmp;
+   tmp = -((a >> 27) & 1); tmp &= ((b & 0xe0e0e0e0) >> 5); hi = hi ^ tmp;
+   tmp = -((a >> 26) & 1); tmp &= ((b & 0xc0c0c0c0) >> 6); hi = hi ^ tmp;
+   tmp = -((a >> 25) & 1); tmp &= ((b & 0x80808080) >> 7); hi = hi ^ tmp;
+   c[0] = lo; c[1] = hi;
+}
+static inline void mpfq_2_64_gf2x_mul2(unsigned long *c, const unsigned long *a,
+			     const unsigned long *b)
+{
+    unsigned long t;
+    unsigned long u[2];
+
+    mpfq_2_64_gf2x_mul1(c, a[0], b[0]);
+    mpfq_2_64_gf2x_mul1(c + 2, a[1], b[1]);
+    t = c[1] ^ c[2];
+    mpfq_2_64_gf2x_mul1(u, a[0] ^ a[1], b[0] ^ b[1]);
+    c[1] = c[0] ^ u[0] ^ t;
+    c[2] = c[3] ^ u[1] ^ t;
+}
+#endif
+
 static inline
 void mpfq_2_64_mul_ur(mpfq_2_64_dst_field K MAYBE_UNUSED, mpfq_2_64_dst_elt_ur t, mpfq_2_64_src_elt s1, mpfq_2_64_src_elt s2)
 {
-    /* 64x64 basecase slice=4 slicenet=sequence sse2=64 w=32 */
-#define SHL(x, r) _mm_slli_epi64((x), (r))
-#define SHR(x, r) _mm_srli_epi64((x), (r))
-#define SHLD(x, r) _mm_slli_si128((x), (r) >> 3)
-#define SHRD(x, r) _mm_srli_si128((x), (r) >> 3)
-    /* s2_input_elements: s2[0] s2[1] 0 0 */
-    __m128i u;
-    __m128i t0;
-    __m128i t1;
-    
-    __m128i g[16];
-    /* sequence update walk */
-    g[0] = _mm_setzero_si128();
-    g[1] = _mm_set_epi32(0, 0, s2[1], s2[0]);
-    g[2] = SHL(g[1], 1);
-    g[3] = g[2] ^ g[1];
-    g[4] = SHL(g[2], 1);
-    g[5] = g[4] ^ g[1];
-    g[6] = SHL(g[3], 1);
-    g[7] = g[6] ^ g[1];
-    g[8] = SHL(g[4], 1);
-    g[9] = g[8] ^ g[1];
-    g[10] = SHL(g[5], 1);
-    g[11] = g[10] ^ g[1];
-    g[12] = SHL(g[6], 1);
-    g[13] = g[12] ^ g[1];
-    g[14] = SHL(g[7], 1);
-    g[15] = g[14] ^ g[1];
-    
-    /* round 0 */
-    u = g[s1[0]       & 15];
-    t0  = u;
-    u = g[s1[0] >>  4 & 15];
-    t0 ^= SHL(u,  4); t1  = SHR(u, 60);
-    u = g[s1[0] >>  8 & 15];
-    t0 ^= SHL(u,  8); t1 ^= SHR(u, 56);
-    u = g[s1[0] >> 12 & 15];
-    t0 ^= SHL(u, 12); t1 ^= SHR(u, 52);
-    u = g[s1[0] >> 16 & 15];
-    t0 ^= SHL(u, 16); t1 ^= SHR(u, 48);
-    u = g[s1[0] >> 20 & 15];
-    t0 ^= SHL(u, 20); t1 ^= SHR(u, 44);
-    u = g[s1[0] >> 24 & 15];
-    t0 ^= SHL(u, 24); t1 ^= SHR(u, 40);
-    u = g[s1[0] >> 28 & 15];
-    t0 ^= SHL(u, 28); t1 ^= SHR(u, 36);
-    u = g[s1[1]       & 15];
-    t0 ^= SHL(u, 32); t1 ^= SHR(u, 32);
-    u = g[s1[1] >>  4 & 15];
-    t0 ^= SHL(u, 36); t1 ^= SHR(u, 28);
-    u = g[s1[1] >>  8 & 15];
-    t0 ^= SHL(u, 40); t1 ^= SHR(u, 24);
-    u = g[s1[1] >> 12 & 15];
-    t0 ^= SHL(u, 44); t1 ^= SHR(u, 20);
-    u = g[s1[1] >> 16 & 15];
-    t0 ^= SHL(u, 48); t1 ^= SHR(u, 16);
-    u = g[s1[1] >> 20 & 15];
-    t0 ^= SHL(u, 52); t1 ^= SHR(u, 12);
-    u = g[s1[1] >> 24 & 15];
-    t0 ^= SHL(u, 56); t1 ^= SHR(u,  8);
-    u = g[s1[1] >> 28 & 15];
-    t0 ^= SHL(u, 60); t1 ^= SHR(u,  4);
-    /* end */
-    
-    /* repair steps */
-    /* repair section 200711-200803 */
-    __m128i v1 = _mpfq_mm_setr_epi32(s1[0], s1[1], s1[0], s1[1]);
-    v1 = SHR(v1, 1);
-    __m128i w;
-    __m128i m = _mpfq_mm_setr_epi32_c(0x77777777, 0x77777777, 0x77777777, 0x77777777);
-    w = -SHR(g[1],63);
-    v1 = v1 & m;
-    t1 ^= v1 & w;
-    w = -SHR(g[2],63);
-    v1 = SHR(v1, 1) & m;
-    t1 ^= v1 & w;
-    w = -SHR(g[4],63);
-    v1 = SHR(v1, 1) & m;
-    t1 ^= v1 & w;
-    
-    /* store result */
-    _mm_storeu_si128((__m128i *) (t + 0), _mm_xor_si128(t0, SHLD(t1, 64)));
-#undef SHL
-#undef SHR
-#undef SHLD
-#undef SHRD
+    mpfq_2_64_gf2x_mul2(t, s1, s2);
 }
 
 /* *Mpfq::gf2n::squaring::code_for_sqr_ur */
diff --git a/fft/mpfq/mpfq.h b/fft/mpfq/mpfq.h
index 9240e1b..30d9cc7 100644
--- a/fft/mpfq/mpfq.h
+++ b/fft/mpfq/mpfq.h
@@ -8,7 +8,15 @@
 #include <stdio.h>
 #include <stdlib.h>
 #include <string.h>
+
+#ifdef  GF2X_HAVE_GMP_H
 #include <gmp.h>
+#elif defined(GF2X_HAVE_MPIR_H)
+#include <mpir.h>
+#else
+#error "make sure gf2x-config-export.h is included before gf2x-cantor-fft.h or mpfq/<anything>.h"
+#endif
+
 
 #ifdef __cplusplus
 extern "C" {
diff --git a/fft/mpfq/x86_64/mpfq_2_128.h b/fft/mpfq/x86_64/mpfq_2_128.h
index bbb1866..f701c33 100644
--- a/fft/mpfq/x86_64/mpfq_2_128.h
+++ b/fft/mpfq/x86_64/mpfq_2_128.h
@@ -11,9 +11,15 @@
 #include <assert.h>
 #include <stdint.h>
 #include <ctype.h>
-#include <emmintrin.h>
 #include <stddef.h>
 #include <stdio.h>
+#ifdef  HAVE_GF2X
+#include "gf2x.h"
+#endif
+#ifdef HAVE_PCLMUL
+#include <wmmintrin.h>
+#endif
+
 #include "assert.h"
 #ifdef	MPFQ_LAST_GENERATED_TAG
 #undef	MPFQ_LAST_GENERATED_TAG
@@ -1031,6 +1034,25 @@ void mpfq_2_128_elt_ur_add(mpfq_2_128_dst_field K MAYBE_UNUSED, mpfq_2_128_dst_e
 static inline
 void mpfq_2_128_mul_ur(mpfq_2_128_dst_field K MAYBE_UNUSED, mpfq_2_128_dst_elt_ur t, mpfq_2_128_src_elt s1, mpfq_2_128_src_elt s2)
 {
+#ifdef  HAVE_GF2X
+    gf2x_mul2(t, s1, s2);
+#elif defined(HAVE_PCLMUL)      /* !HAVE_GF2X */
+#define PXOR(lop, rop) _mm_xor_si128((lop), (rop))
+#define PZERO    _mm_setzero_si128()
+    __m128i ss1 = _mm_loadu_si128((__m128i *)s1);
+    __m128i ss2 = _mm_loadu_si128((__m128i *)s2);
+    __m128i t00 = _mm_clmulepi64_si128(ss1, ss2, 0);
+    __m128i t11 = _mm_clmulepi64_si128(ss1, ss2, 0x11);
+    ss1 = PXOR(ss1, _mm_shuffle_epi32(ss1, _MM_SHUFFLE(1,0,3,2)));
+    ss2 = PXOR(ss2, _mm_shuffle_epi32(ss2, _MM_SHUFFLE(1,0,3,2)));
+    __m128i tk = _mm_clmulepi64_si128(ss1, ss2, 0);
+    tk = PXOR(tk, PXOR(t00, t11));
+    /* store result */
+    _mm_storeu_si128((__m128i *)(t),  PXOR(t00, _mm_unpacklo_epi64(PZERO, tk)));
+    _mm_storeu_si128((__m128i *)(t+2),PXOR(t11, _mm_unpackhi_epi64(tk, PZERO)));
+#undef PZERO
+#undef PXOR
+#else   /* !HAVE_GF2X && !HAVE_PCLMUL */
 #define SHL(x, r) _mm_slli_epi64((x), (r))
 #define SHR(x, r) _mm_srli_epi64((x), (r))
 #define SHLD(x, r) _mm_slli_si128((x), (r) >> 3)
@@ -1119,6 +1141,7 @@ void mpfq_2_128_mul_ur(mpfq_2_128_dst_field K MAYBE_UNUSED, mpfq_2_128_dst_elt_u
 #undef XOREQ
 #undef PXOR
 #undef PAND
+#endif   /* !HAVE_GF2X && !HAVE_PCLMUL */
 }
 
 /* *Mpfq::gf2n::squaring::code_for_sqr_ur */
diff --git a/fft/mpfq/x86_64/mpfq_2_64.h b/fft/mpfq/x86_64/mpfq_2_64.h
index 4cfb9c2..44698b4 100644
--- a/fft/mpfq/x86_64/mpfq_2_64.h
+++ b/fft/mpfq/x86_64/mpfq_2_64.h
@@ -11,9 +11,15 @@
 #include <assert.h>
 #include <stdint.h>
 #include <ctype.h>
-#include <emmintrin.h>
 #include <stddef.h>
 #include <stdio.h>
+#ifdef  HAVE_GF2X
+#include "gf2x.h"
+#endif
+#ifdef HAVE_PCLMUL
+#include <wmmintrin.h>
+#endif
+
 #include "assert.h"
 #ifdef	MPFQ_LAST_GENERATED_TAG
 #undef	MPFQ_LAST_GENERATED_TAG
@@ -935,6 +938,13 @@ void mpfq_2_64_elt_ur_add(mpfq_2_64_dst_field K MAYBE_UNUSED, mpfq_2_64_dst_elt_
 static inline
 void mpfq_2_64_mul_ur(mpfq_2_64_dst_field K MAYBE_UNUSED, mpfq_2_64_dst_elt_ur t, mpfq_2_64_src_elt s1, mpfq_2_64_src_elt s2)
 {
+#ifdef HAVE_GF2X
+    gf2x_mul1(t, s1, s2);
+#elif defined(HAVE_PCLMUL)      /* !HAVE_GF2X */
+    __m128i ss1 = _mm_setr_epi64((__m64) s1[0], (__m64) 0LL);
+    __m128i ss2 = _mm_setr_epi64((__m64) s2[0], (__m64) 0LL);
+    _mm_storeu_si128((__m128i *)(t),  _mm_clmulepi64_si128(ss1, ss2, 0));
+#else
        unsigned long hi, lo;
        unsigned long A[16];
        unsigned long a = s2[0];
@@ -999,6 +1005,7 @@ void mpfq_2_64_mul_ur(mpfq_2_64_dst_field K MAYBE_UNUSED, mpfq_2_64_dst_elt_ur t
        }
        t[0] = lo;
        t[1] = hi;
+#endif
 }
 
 /* *Mpfq::gf2n::squaring::code_for_sqr_ur */
